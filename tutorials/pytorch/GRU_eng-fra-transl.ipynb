{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to French Translation \n",
    "## Seq2Seq (Encoder/Decoder) Model From Scratch\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html  \n",
    "\n",
    "\n",
    "While recurrent nets allow us to process sequential data, things get tricky with *sequence length*. We can use an RNN (or variant) to process a sequence and convert that into a classification or regression (for example, language of origin for a name). We can even use a single RNN to learn to predict the next character in a sequence of text, allowing us to generate text.  \n",
    "However, things break down when we want to predict a **sequence** of outputs, rather than a single/time-invariant output (like a class or a preceding character).  \n",
    "This is where the encoder/decoder model comes in - one RNN is used to process the sequential data, producing a single output (the last hidden state at the end of its loop) which ideally encodes all the useful information about the sequence.  \n",
    "Then a seperate RNN, the decoder, takes in the encoder's output and uses it to generate a sequence of output, with some other tricks lending a hand.  \n",
    "\n",
    "### Encoder:  \n",
    "I use a GRU as my recurrent component and additionally use an 'embedding layer' before the GRU. Thus the encoder receives a character, embeds the character, and passes the embedding and the hidden state into the GRU. The GRU uses the embedding and hidden state to update the hidden state. This repeats for every character in the sequence, and the final hidden state is the GRU's output.  \n",
    "\n",
    "### Simple Decoder:  \n",
    "The last output of the encoder (ie, last hidden state of the GRU) is also known as the 'context vector' since it has seen the entire input sequence. For a simple seq2seq model implementation we can just use this last vector as the initial hidden state for the GRU in the decoder component.  \n",
    "The GRU also receives an input character - which to start is a special \"start of phrase\" token. Once again we can use a learnable embedding layer to embed this token before passing it into the GRU.  \n",
    "For every input character, the decoder outputs an updated hidden state and a prediction of the next character. These get passed back into the GRU until it predicts the special \"end of phrase\" token.    \n",
    "\n",
    "Finally, we backprop through the whole network and update its parameters.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "# Model/Train Helpers\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslGRU:\n",
    "    def __init__(self, input_size, \n",
    "                       enc_embed_dim, dec_embed_dim,\n",
    "                       enc_hidden_size, dec_hidden_size, \n",
    "                       output_size\n",
    "                ) -> None:\n",
    "        \"\"\"\n",
    "        Define a GRU.\n",
    "        input_size = number of elements in one-hot encoded vector for a single input.\n",
    "        hidden_size = desired number of elements in the hidden and cell states\n",
    "        output_size = None unless want a linear, dense layer ontop of the GRU converting last hidden state to logits of shape (output_size, 1)\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.enc_embed_dim = enc_embed_dim\n",
    "        self.dec_embed_dim = dec_embed_dim\n",
    "        \n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.params = []\n",
    "\n",
    "    def init_weights(self, lam=0.01, seed=123) -> None:\n",
    "        \"\"\"Initialize weight tensors for the model.\"\"\"\n",
    "        g = torch.Generator().manual_seed(seed)\n",
    "        self._init_enc_weights(lam=lam, g=g)\n",
    "        self._init_dec_weights(lam=lam, g=g)\n",
    "        \n",
    "        for p in self.params:\n",
    "            p.requires_grad = True \n",
    "        self.n_parameters = self._count_params()\n",
    "\n",
    "    def init_hidden(self) -> torch.tensor:\n",
    "        \"\"\"Initialize hidden state. Returns: hidden\"\"\"\n",
    "        hidden = torch.zeros((self.hidden_size, 1))  #(hidden size , batch size)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "    def _init_enc_weights(self, g, lam=0.01, ) -> None:\n",
    "        \"\"\"Initialize weight tensors for the decoder model.\"\"\"\n",
    "        concat_size = self.enc_embed_dim + self.enc_hidden_size\n",
    "\n",
    "        self.enc_embed = torch.rand((self.input_size, self.enc_embed_dim), generator=g) * lam\n",
    "\n",
    "        self.enc_W_reset = torch.rand((self.enc_hidden_size, concat_size), generator=g) * lam\n",
    "        self.enc_br = torch.zeros((self.enc_hidden_size, 1)) * lam\n",
    "        self.enc_W_update = torch.rand((self.enc_hidden_size, concat_size), generator=g) * lam\n",
    "        self.enc_bu = torch.zeros((self.enc_hidden_size, 1)) * lam\n",
    "        self.enc_W_htilde = torch.rand((self.enc_hidden_size, concat_size), generator=g) * lam\n",
    "        #self.bh = torch.zeros((self.hidden_size, 1)) * lam\n",
    "        \n",
    "        self.params += [self.enc_embed, self.enc_W_reset, self.enc_br, self.enc_W_update, self.enc_bu, self.enc_W_htilde]\n",
    "    \n",
    "    def _init_dec_weights(self, g, lam=0.01) -> None:\n",
    "        \"\"\"Initialize weight tensors for the encoder.\"\"\"\n",
    "        concat_size = self.dec_embed_dim + self.dec_hidden_size\n",
    "\n",
    "        self.dec_embed = torch.rand((self.input_size, self.dec_embed_dim), generator=g) * lam\n",
    "\n",
    "        self.dec_W_reset = torch.rand((self.dec_hidden_size, concat_size), generator=g) * lam\n",
    "        self.dec_br = torch.zeros((self.dec_hidden_size, 1)) * lam\n",
    "        self.dec_W_update = torch.rand((self.dec_hidden_size, concat_size), generator=g) * lam\n",
    "        self.dec_bu = torch.zeros((self.dec_hidden_size, 1)) * lam\n",
    "        self.dec_W_htilde = torch.rand((self.dec_hidden_size, concat_size), generator=g) * lam\n",
    "        #self.bh = torch.zeros((self.hidden_size, 1)) * lam\n",
    "        \n",
    "        # FC\n",
    "        self.W_h2o = torch.rand((self.output_size, self.dec_hidden_size), generator=g) * lam\n",
    "        self.b_h20 = torch.zeros((self.output_size, 1)) * lam\n",
    "        self.params += [self.dec_embed, self.dec_W_reset, self.dec_br, self.dec_W_update, self.dec_bu, self.dec_W_htilde, self.W_h2o, self.b_h20]\n",
    "   \n",
    "\n",
    "    def encoder(self, hidden_prev, x_tensor_t,):\n",
    "        \"ENCODER AT STEP T\"\n",
    "        input = self.enc_embed[x_tensor_t]\n",
    "        hidden_new = self.gru(input, hidden_prev)\n",
    "        return hidden_new\n",
    "    \n",
    "    def simple_decoder(self, context_vector, input_char_t):\n",
    "        \"DECODER AT STEP T\"\n",
    "        input = self.dec_embed[input_char_t]\n",
    "        hidden_new = self.gru(input, context_vector)\n",
    "        \n",
    "        # run hidden state through linear softmax layer to predict next char\n",
    "        output = self.linear_softmax(hidden_new)\n",
    "        next_input_char = torch.argmax(output, dim=1)\n",
    "        return next_input_char, hidden_new\n",
    "\n",
    "    \n",
    "    def gru(self, input, hidden) -> torch.tensor:\n",
    "        \"\"\"One forward step in a GRU cell to update hidden state. Returns: hidden_new\"\"\"\n",
    "        # Concatenate inputs with incoming hidden state\n",
    "        concat_raw = torch.cat((input, hidden), dim=0)\n",
    "\n",
    "        # Calc reset gate and apply to hidden state to produce gated/reset hidden state\n",
    "        r_gate = torch.sigmoid(self.W_reset @ concat_raw + self.br)\n",
    "        hidden_reset = hidden * r_gate\n",
    "\n",
    "        # Concatenate inputs with gated hidden state\n",
    "        concat_gated = torch.cat((input, hidden_reset), dim=0)\n",
    "        # Calculate h tilde, the proposed new hidden state, using the gated concatenation\n",
    "        h_tilde = torch.tanh(self.W_htilde @ concat_gated)\n",
    "\n",
    "        # Calc update gate using the raw/ungated concatenation\n",
    "        u_gate = torch.sigmoid(self.W_update @ concat_raw + self.bu)\n",
    "\n",
    "        # Update hidden state with (1 - update gate) * hidden_t-1 + (update gate * h tilde):\n",
    "        hidden_new = (1 - u_gate) * hidden + u_gate * h_tilde\n",
    "        \n",
    "        return hidden_new\n",
    "    \n",
    "    def linear_softmax(self, input):\n",
    "        return torch.softmax( (self.W_h2o @ input) + self.b_h20 )\n",
    "\n",
    "\n",
    "    def backprop_update(self, lr) -> None:\n",
    "        \n",
    "        # ensure gradients are zerod\n",
    "        for p in self.params:\n",
    "            p.grad = None\n",
    "\n",
    "        # backprop\n",
    "        self.loss.backward()\n",
    "\n",
    "        # update\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is None:\n",
    "                print(i) ##silly debugging\n",
    "            p.data += -lr * p.grad\n",
    "\n",
    "\n",
    "    def _count_params(self):\n",
    "        n_params = 0\n",
    "        for p in self.params:\n",
    "            n_params += p.nelement()\n",
    "        return n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y=None, hidden=None, truncate=None):\n",
    "    \"\"\"\n",
    "    Perform an entire forward pass of a sample to calculate outputs and calculate loss if y is provided.\n",
    "    Returns logits, loss.\n",
    "    \"\"\"\n",
    "    # Initialize states with zeroes\n",
    "    if hidden is None:\n",
    "        hidden = self.init_states()\n",
    "    \n",
    "    \n",
    "    # Pass through X sequentially and index embedding by current character\n",
    "    # Pass character embedding and previous hidden state to GRU\n",
    "    loss = 0\n",
    "    for t in range(x.shape[0]):\n",
    "        model.encoder(hidden, )\n",
    "\n",
    "        # If output shape is not equal to hidden shape, pass through a linear layer to calculate final logits\n",
    "        if self.output_size is not None:\n",
    "            logits = (self.W_h2o @ hidden) + self.b_h20\n",
    "        else:\n",
    "            logits = hidden\n",
    "        full_logits[t] = logits.squeeze()\n",
    "    \n",
    "        # Calculate loss \n",
    "        if y is not None:\n",
    "            y_size = self.output_size if self.output_size is not None else self.hidden_size\n",
    "            y_ohe = torch.zeros(y_size)\n",
    "            y_ohe[y[t]] = 1.0\n",
    "            loss += torch.nn.functional.cross_entropy(logits.squeeze(), y_ohe)\n",
    "\n",
    "            # if x.shape[0]-t == truncate:\n",
    "            #     loss.backward()\n",
    "            #     loss.detach()\n",
    "\n",
    "    self.loss = loss\n",
    "\n",
    "    return full_logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_data(english, french, stoi, special_char:str):\n",
    "    \"\"\"\n",
    "    Takes words list and breaks into training samples such that\n",
    "    block_size characters are used to predict the following character.\n",
    "    Returns X, Y (inputs and labels), where each sample in X is a tensor containing block_size elements\n",
    "    and each sample in Y is a tensor containing one element.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data\n",
    "    ## block_size = context length: how many chars do we use to predict the next?\n",
    "    X, Y = [], []\n",
    "    for en, fr in zip(english, french):\n",
    "        \n",
    "        diff = len(fr) - len(en)\n",
    "        if diff > 0:\n",
    "            add_to_en = abs(diff)\n",
    "            add_to_fr = 0\n",
    "        elif diff < 0:\n",
    "            add_to_en = 0\n",
    "            add_to_fr = abs(diff)\n",
    "        else:\n",
    "            add_to_en = 0\n",
    "            add_to_fr = 0\n",
    "\n",
    "        english_ix, french_ix = [], []\n",
    "        for ch in en:\n",
    "            english_ix.append(stoi[ch])\n",
    "        english_ix.append(stoi[special_char])\n",
    "        english_ix += [stoi[special_char]] * add_to_en\n",
    "\n",
    "        for ch in fr:\n",
    "            french_ix.append(stoi[ch])\n",
    "        french_ix.append(stoi[special_char])\n",
    "        french_ix += [stoi[special_char]] * add_to_fr\n",
    "\n",
    "        X.append(torch.tensor(english_ix))\n",
    "        Y.append(torch.tensor(french_ix))\n",
    "    # X = torch.tensor(X)\n",
    "    # Y = torch.tensor(Y)\n",
    "    # n_samples = X.shape[0]\n",
    "    # print(f\"{ n_samples = }\")\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def split_samples(inputs, labels, frac=0.8, seed=123):\n",
    "    \"Split xs and ys (inputs and labels) into train and test sets\"\n",
    "    \n",
    "    assert len(inputs)==len(labels), f\"{len(inputs) = } which does not match {len(labels) = }\"\n",
    "    # generate a list of indices to exclude. Turn in into a set for O(1) lookup time\n",
    "    random.seed(seed)\n",
    "    indx = list(set(random.sample(list(range(len(inputs))), int(frac*len(inputs)))))\n",
    "\n",
    "    x_mask = torch.zeros((len(inputs)), dtype=torch.bool) #False\n",
    "    x_mask[indx] = True\n",
    "\n",
    "    y_mask = torch.zeros((len(inputs)), dtype=torch.bool) #False\n",
    "    y_mask[indx] = True\n",
    "\n",
    "    train_x = inputs[x_mask]\n",
    "    train_y = labels[y_mask]\n",
    "\n",
    "    test_x = inputs[~x_mask]\n",
    "    test_y = labels[~y_mask]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FR_CHRS = 100\n",
    "english, french = [],[]\n",
    "\n",
    "matches = [\"(\", \"‽\", \"…\", \"€\"]\n",
    "with open(\"./data/rnn_tut_data/eng-fra.txt\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip()\n",
    "        line = line.replace(u\"\\u202f\", \" \")\n",
    "        line = line.replace(u\"\\u3000\", \" \")\n",
    "        line = line.replace(u\"\\u2000\", \" \")\n",
    "        line = line.replace(u\"\\u200b\", \" \")\n",
    "        line = line.replace(u\"\\xa0\", \" \")\n",
    "        line = line.replace(u\"\\xad\", \" \")\n",
    "        line = line.replace(u\"\\u2009\", \" \")\n",
    "        line = line.replace(\"ú\", \"u\")\n",
    "        line = line.replace(\"–\", \"-\")\n",
    "        line = line.replace(\"а\", \"a\")\n",
    "        line = line.replace(\"‐\", \"-\")\n",
    "        if any(s in line for s in matches): ##removes some edge cases\n",
    "            pass\n",
    "        else:        \n",
    "            eng, fra = line.split('\\t')\n",
    "        \n",
    "        if (len(fra)>MAX_FR_CHRS):\n",
    "            pass\n",
    "        else:\n",
    "            english.append(eng)\n",
    "            french.append(fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135332\n",
      "135332\n",
      "83\n",
      "104\n",
      "104\n",
      "max french length =  100 chars\n"
     ]
    }
   ],
   "source": [
    "print(len(english))\n",
    "print(len(french))\n",
    "\n",
    "eng_chars = set(''.join(english))\n",
    "fra_chars = set(''.join(french))\n",
    "all_chars = set(''.join(english + french))\n",
    "print(len(eng_chars))\n",
    "print(len(fra_chars))\n",
    "print(len(all_chars))\n",
    "\n",
    "print(\"max french length = \", len(max(french, key=len)), \"chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stoi = {s:i+1 for i, s in enumerate(all_chars)} ##create dictionary mapping from char to int\n",
    "stoi['*'] = 0 #special char\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "\n",
    "corpus = ''.join(english+french)\n",
    "count_letters = dict()\n",
    "\n",
    "for c in all_chars:\n",
    "    count_letters[c] = corpus.count(c)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(range(len(count_letters)), list(count_letters.values()), align='center')\n",
    "plt.xticks(range(len(count_letters)), list(count_letters.keys()))\n",
    "plt.title(\"Character Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51259\n"
     ]
    }
   ],
   "source": [
    "samples = 300\n",
    "xs, ys = words_to_data(english[:samples], french[:samples], stoi, special_char=\"*\")\n",
    "\n",
    "n_letters = len(stoi)\n",
    "hidden_size = 64\n",
    "emb_dim = 33\n",
    "\n",
    "model = TranslGRU(input_size=n_letters,\n",
    "                  enc_embed_dim=emb_dim,\n",
    "                  dec_embed_dim=emb_dim,\n",
    "                  enc_hidden_size=hidden_size,\n",
    "                  dec_hidden_size=hidden_size,                  \n",
    "                  output_size=n_letters)\n",
    "model.init_weights(lam=0.01)\n",
    "\n",
    "print(model.n_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0248, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    s_ix = 200 #random.randint(0, len(x)-1)\n",
    "\n",
    "    x_i, y_i = xs[s_ix], ys[s_ix]\n",
    "    # x_ohe = torch.nn.functional.one_hot(x_i, n_letters)\n",
    "    # x_ohe = torch.unsqueeze(x_ohe, dim=1) #insert 'batch' dim\n",
    "\n",
    "    logits, loss = model.forward(x_i, y_i)\n",
    "\n",
    "    model.backprop_update(lr=0.1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAA\n",
      "Appelle Tom.*\n"
     ]
    }
   ],
   "source": [
    "phrase = []\n",
    "truth = []\n",
    "for i in range(logits.shape[0]):\n",
    "    indx = torch.argmax(logits[0]).item()\n",
    "    phrase.append(itos[indx])\n",
    "    truth.append(itos[y_i[i].item()])\n",
    "\n",
    "print(\"\".join(phrase)) \n",
    "print(\"\".join(truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = torch.zeros((n_letters, 3))\n",
    "logs[:, 0] = logits.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.softmax(logits, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c4359ed68c894e31dfa741bacd50703ee9ca4c289f19062f47d11ef9a0ee7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
