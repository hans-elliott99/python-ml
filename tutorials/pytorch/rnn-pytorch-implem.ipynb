{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "# Text preprocessing\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# Model/Train Helpers\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-Level RNN for Classifying Name Origins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/rnn_tut_data/names\\\\Arabic.txt', './data/rnn_tut_data/names\\\\Chinese.txt', './data/rnn_tut_data/names\\\\Czech.txt', './data/rnn_tut_data/names\\\\Dutch.txt', './data/rnn_tut_data/names\\\\English.txt', './data/rnn_tut_data/names\\\\French.txt', './data/rnn_tut_data/names\\\\German.txt', './data/rnn_tut_data/names\\\\Greek.txt', './data/rnn_tut_data/names\\\\Irish.txt', './data/rnn_tut_data/names\\\\Italian.txt', './data/rnn_tut_data/names\\\\Japanese.txt', './data/rnn_tut_data/names\\\\Korean.txt', './data/rnn_tut_data/names\\\\Polish.txt', './data/rnn_tut_data/names\\\\Portuguese.txt', './data/rnn_tut_data/names\\\\Russian.txt', './data/rnn_tut_data/names\\\\Scottish.txt', './data/rnn_tut_data/names\\\\Spanish.txt', './data/rnn_tut_data/names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "def findFiles(path): return glob.glob(path)\n",
    "print(findFiles('./data/rnn_tut_data/names/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\n",
      "n_letters = 57\n"
     ]
    }
   ],
   "source": [
    "# All letters in the vocabulary\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "print(all_letters)\n",
    "print(f\"{n_letters = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slusarski'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )    \n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "\n",
    "# example\n",
    "unicodeToAscii('Ślusàrski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_categories = 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Abandonato',\n",
       " 'Abatangelo',\n",
       " 'Abatantuono',\n",
       " 'Abate',\n",
       " 'Abategiovanni',\n",
       " 'Abatescianni',\n",
       " 'Abba',\n",
       " 'Abbadelli',\n",
       " 'Abbascia',\n",
       " 'Abbatangelo']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/rnn_tut_data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "print(f\"{n_categories = }\")\n",
    "\n",
    "category_lines['Italian'][:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data -> Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1 ##index the letter in the onehot-encoding\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print( letterToTensor(\"J\") )\n",
    "print( (lineToTensor(\"Hello\")).shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    \"\"\"Decode model output into category prediction\"\"\"\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Russian / line = Yakunichev\n",
      "category = Vietnamese / line = Doan\n",
      "category = Italian / line = Alunni\n",
      "category = Spanish / line = Rodriquez\n",
      "category = Dutch / line = Stoep\n",
      "category = Irish / line = Rinn\n",
      "category = Scottish / line = Sinclair\n",
      "category = Vietnamese / line = Ly\n",
      "category = English / line = Goodridge\n",
      "category = English / line = Noonan\n"
     ]
    }
   ],
   "source": [
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    \"\"\"Randomly pick training examples\"\"\"\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBasic RNN Diagram\\n\\n\\n[input]          [hidden]<---\\n    |_____      _____|      |\\n          |    |            |\\n        [combined (+)]      |\\n    _____|          |       |\\n   |                |       |\\n  (i2o)            (i2h)    |      (Linear NN layers)\\n   |                |       |\\n[softmax]           |       |\\n   |                ⬇       |       \\n   ⬇             [hidden]--->\\n[OUTPUT]\\n\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Basic RNN Diagram\n",
    "\n",
    "\n",
    "[input]          [hidden]<---\n",
    "    |_____      _____|      |\n",
    "          |    |            |\n",
    "        [combined (cat)]    |\n",
    "    _____|          |       |\n",
    "   |                |       |\n",
    "  (i2o)            (i2h)    |      (Linear NN 'hidden layers')\n",
    "   |                |       |       (could apply an activation function)\n",
    "[softmax]           |       |\n",
    "   |                ⬇       |       \n",
    "   ⬇             [hidden]--->\n",
    "[OUTPUT]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(in_features = input_size + hidden_size, \n",
    "                            out_features = hidden_size)\n",
    "        self.i2o = nn.Linear(in_features = input_size + hidden_size,\n",
    "                            out_features = output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # reinitialize weights if recalling __init__\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"Concatenate the inputs with the hidden state and forward pass through the linear layers (+ softmax).\"\"\"\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "        hidden = self.tanh(self.i2h(combined))\n",
    "        output = self.softmax(self.i2o(combined))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"initialization for the hidden state with the zero vector.\"\"\"\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Reinitialize weights and biases.\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight.data) ##since using tanh\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Albert\n",
      "torch.Size([1, 18])\n",
      "('Russian', 14)\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL (decided to use 2 RNN layers)\n",
    "torch.manual_seed(12345)\n",
    "n_hidden = 128\n",
    "\n",
    "rnn0 = RNN(input_size=n_letters, hidden_size=n_hidden, output_size=n_categories)\n",
    "# rnn1 = RNN(input_size=n_hidden, hidden_size=n_hidden, output_size=n_categories) ##input needs to match output of last layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example output\n",
    "print(\"> Albert\")\n",
    "input = lineToTensor(\"Albert\")\n",
    "hidden0 = torch.zeros(1, n_hidden)\n",
    "hidden1 = torch.zeros(1, n_hidden)\n",
    "\n",
    "output0, next_hidden0 = rnn0(input[0], hidden0)\n",
    "# output, next_hidden1  = rnn1(output0, hidden1)\n",
    "output = output0\n",
    "\n",
    "print(output.shape) ##1 x n_categories, where every category is the likelihood of that category.\n",
    "print(categoryFromOutput(output)) ## decoded prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27156"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = 0\n",
    "for p in rnn0.parameters():\n",
    "    params += p.nelement()\n",
    "params * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train function (one training step)\n",
    "\n",
    "def train_step(category_tensor, line_tensor, criterion, lr):\n",
    "    \"\"\"Perform one forward and backward pass, and update model's weights.\"\"\"\n",
    "    \n",
    "    # Initialize the hidden states (with zeros)\n",
    "    hidden0 = rnn0.init_hidden() \n",
    "    # hidden1 = rnn1.init_hidden()\n",
    "\n",
    "    # Zero and gradients\n",
    "    rnn0.zero_grad()\n",
    "    # rnn1.zero_grad()\n",
    "\n",
    "    # FORWARD PASS\n",
    "    for i in range(line_tensor.shape[0]):\n",
    "        # FEED IN EACH CHARACTER OF THE LINE\n",
    "        ## GET THE OUTPUT AND THE NEW HIDDEN STATE\n",
    "        output0, hidden0 = rnn0(line_tensor[i], hidden0)\n",
    "        # output1, hidden1 = rnn1(output0, hidden1)\n",
    "        output = output0\n",
    "    \n",
    "    # BACKWARD PASS\n",
    "    loss = criterion(output, category_tensor) ##provide the model's output (predicted categories) and the true categories\n",
    "    loss.backward() #backprop\n",
    "\n",
    "    # UPDATE\n",
    "    for p in rnn0.parameters():\n",
    "        p.data += -lr * p.grad\n",
    "    # for p in rnn1.parameters():\n",
    "    #     p.data += -lr * p.grad\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abandonato']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_lines['Italian'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "\n",
    "n_iters = 10_000\n",
    "print_every = 1000\n",
    "plot_every = 100\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 10% (0m 2s) 0.0004 Abandonato / Italian ✓\n",
      "2000 20% (0m 4s) 0.0002 Abandonato / Italian ✓\n",
      "3000 30% (0m 6s) 0.0001 Abandonato / Italian ✓\n",
      "4000 40% (0m 8s) 0.0001 Abandonato / Italian ✓\n",
      "5000 50% (0m 11s) 0.0001 Abandonato / Italian ✓\n",
      "6000 60% (0m 13s) 0.0001 Abandonato / Italian ✓\n",
      "7000 70% (0m 16s) 0.0000 Abandonato / Italian ✓\n",
      "8000 80% (0m 18s) 0.0000 Abandonato / Italian ✓\n",
      "9000 90% (0m 21s) 0.0000 Abandonato / Italian ✓\n",
      "10000 100% (0m 23s) 0.0000 Abandonato / Italian ✓\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.NLLLoss()\n",
    "test_1_sample = True\n",
    "\n",
    "start = time.time()\n",
    "for iter in range(1, n_iters+1):\n",
    "    # Get a batch (a random training example)\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    if test_1_sample:\n",
    "        category, line = \"Italian\", \"Abandonato\"\n",
    "        line_tensor = lineToTensor(line)\n",
    "        category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "\n",
    "    # Perforam a train step and record loss\n",
    "    output, loss = train_step(category_tensor, line_tensor, lr=lr, criterion=loss_fn)\n",
    "    current_loss += loss\n",
    "\n",
    "    # print updates\n",
    "    if (iter % print_every) == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if (iter % plot_every) == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn0.init_hidden()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn0(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of correct guesses in a confusion matrix (2x2 torch tensor)\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "n_confusion = 10000\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# # Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line))\n",
    "\n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(n_predictions, 1, True)\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(n_predictions):\n",
    "            value = topv[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Dovesky\n",
      "(-0.00) Italian\n",
      "(-9.48) Arabic\n",
      "(-9.50) Dutch\n",
      "\n",
      "> Jackson\n",
      "(-0.00) Italian\n",
      "(-9.78) Polish\n",
      "(-9.90) Japanese\n",
      "\n",
      "> Satoshi\n",
      "(-0.00) Italian\n",
      "(-9.30) Polish\n",
      "(-9.45) Japanese\n",
      "\n",
      "> Abandonato\n",
      "(-0.00) Italian\n",
      "(-12.71) Polish\n",
      "(-12.72) English\n"
     ]
    }
   ],
   "source": [
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')\n",
    "predict('Abandonato')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c4359ed68c894e31dfa741bacd50703ee9ca4c289f19062f47d11ef9a0ee7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
