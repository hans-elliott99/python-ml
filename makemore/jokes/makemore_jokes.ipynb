{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For neural net\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "# For text\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_joke_data(jokes, block_size, words):\n",
    "    \"\"\"\n",
    "    Takes words list and breaks into training samples based on the desired model-type. For example,\n",
    "    a bigram model where n=2 or a trigram model where n=3. \n",
    "    Returns xs and ys (inputs and labels).\n",
    "    \"\"\"\n",
    "    # Init dicts\n",
    "    itow = {i+1 : w for i, w in enumerate(sorted(words))}\n",
    "    itow[0] = '.'\n",
    "    wtoi = {w : i for i, w in itow.items()}\n",
    "    n = block_size + 1\n",
    "\n",
    "    # Create samples\n",
    "    X, Y = [], []\n",
    "    for j in jokes:\n",
    "        context = [0] * block_size\n",
    "        word_bag = j.split(' ') + ['.']  ##add special end characters\n",
    "        word_bag = [w for w in word_bag if w != \"\"] ##remove any blank strings that get created\n",
    "        for w in word_bag:\n",
    "            ix = wtoi[w]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            # print([itow[c] for c in context], [itow[ix]])\n",
    "\n",
    "            context = context[1:] + [ix]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "        \n",
    "    n_samples = X.shape[0]\n",
    "    print(f\"{ n_samples = }\")\n",
    "\n",
    "    \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_samples(inputs, labels, frac=0.8, seed=123):\n",
    "    \"Split xs and ys (inputs and labels) into train and test sets\"\n",
    "    \n",
    "    assert len(inputs)==len(labels), f\"{len(inputs) = } which does not match {len(labels) = }\"\n",
    "    # generate a list of indices to exclude. Turn in into a set for O(1) lookup time\n",
    "    random.seed(seed)\n",
    "    indx = list(set(random.sample(list(range(len(inputs))), int(frac*len(inputs)))))\n",
    "\n",
    "    x_mask = torch.zeros((len(inputs)), dtype=torch.bool) #False\n",
    "    x_mask[indx] = True\n",
    "\n",
    "    y_mask = torch.zeros((len(inputs)), dtype=torch.bool) #False\n",
    "    y_mask[indx] = True\n",
    "\n",
    "    train_x = inputs[x_mask]\n",
    "    train_y = labels[y_mask]\n",
    "\n",
    "    test_x = inputs[~x_mask]\n",
    "    test_y = labels[~y_mask]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLinerMLP:\n",
    "\n",
    "    def __init__(self, block_size, words):\n",
    "        \"\"\"\n",
    "        An instance of an MLP where 'block_size' defines the number of characters used \n",
    "        to predict the next character (the block size or context).\n",
    "        \"\"\"\n",
    "        self.n_inputs = block_size ##the number of inputs (ie, excluding the label)\n",
    "\n",
    "        # Init dicts\n",
    "        self.itow = {i+1 : w for i, w in enumerate(sorted(words))}\n",
    "        self.itow[0] = '.'\n",
    "        self.wtoi = {w : i for i, w in itow.items()}\n",
    "\n",
    "        self.n_outputs = int(len(self.itow))\n",
    "        \n",
    "         \n",
    "    def initialize_weights(self,\n",
    "                           embedding_dimensions=2,\n",
    "                           hidden_layer_neurons=100, \n",
    "                           generator=None):\n",
    "        \"Randomly initialize the model's weights.\"\n",
    "        self.hl_neurons = hidden_layer_neurons\n",
    "        self.emb_dim = embedding_dimensions\n",
    "\n",
    "        # INITALIZE NETWORK WEIGHTS\n",
    "        n_inputs = self.n_inputs          ##number of inputs per sample (the block size)\n",
    "        words = self.n_outputs            ##number of words in vocab\n",
    "        emb_dim = embedding_dimensions    ##dimensions of embedding space\n",
    "        hl_neurons = hidden_layer_neurons ##number of neurons in hidden layer\n",
    "\n",
    "\n",
    "        self.C = torch.randn((words, emb_dim), generator=generator, requires_grad=True)\n",
    "\n",
    "        # self.W1 = torch.randn((emb_dim*n_inputs, hl_neurons), generator=generator, requires_grad=True)\n",
    "        self.W1 = self._xavier_init(emb_dim*n_inputs, hl_neurons, generator, requires_grad=True)\n",
    "        self.b1 = torch.zeros(hl_neurons, requires_grad=True)\n",
    "\n",
    "        # self.W2 = torch.randn((hl_neurons, words), generator=generator, requires_grad=True)\n",
    "        self.W2 = self._xavier_init(hl_neurons, words, generator, requires_grad=True)\n",
    "        self.b2 = torch.zeros(words, requires_grad=True)\n",
    "\n",
    "        self.parameters = [self.C, self.W1, self.b1, self.W2, self.b2]\n",
    "        for p in self.parameters:\n",
    "            p.requires_grad=True\n",
    "        print(f\"Model params = { sum(p.nelement() for p in self.parameters) }\")\n",
    "\n",
    "    def _xavier_init(self, n_inputs, n_neurons, generator=None, requires_grad=False):\n",
    "        \"\"\"My implementation of xavier-normal weight initialization for tanh layers\"\"\"\n",
    "        with torch.no_grad():\n",
    "            lower, upper = -(1.0 / math.sqrt(n_inputs)), (1.0 / math.sqrt(n_inputs))\n",
    "            W = lower + torch.rand((n_inputs, n_neurons), generator=generator) * (upper - lower)\n",
    "        W.requires_grad = requires_grad\n",
    "        return W\n",
    "\n",
    "\n",
    "    def forward_pass(self, xs, ys=None, regularization=0):\n",
    "        \"Perform a forward pass of the inputs (xs) through the network. If ys are provided, loss will be evaluated.\"\n",
    "        # forward pass\n",
    "        n_samples = xs.shape[0]\n",
    "        n_inputs = self.n_inputs\n",
    "        hl_neurons = self.hl_neurons\n",
    "        emb_dim = self.emb_dim\n",
    "\n",
    "        parameters = self.parameters\n",
    "\n",
    "        assert n_inputs == xs.shape[1], f\"n_inputs ({n_inputs}) does not match the xs.shape[1]\"\n",
    "\n",
    "        # Forward pass\n",
    "        emb = self.C[xs]\n",
    "        h = torch.tanh( emb.view(-1, n_inputs*emb_dim) @ self.W1 + self.b1 )   \n",
    "        logits = h @ self.W2 + self.b2\n",
    "        # predicted probabilities\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        # loss\n",
    "        loss = None\n",
    "        if ys is not None: #eval loss\n",
    "            loss = F.cross_entropy(logits, ys)\n",
    "            if regularization > 0.0:       \n",
    "                for p in self.parameters:\n",
    "                    loss += regularization*(p**2).mean()\n",
    "            self.loss = loss\n",
    "        \n",
    "        return probs, loss\n",
    "                \n",
    "\n",
    "    def backprop_update(self, lr=0.1):\n",
    "        \"Gradient descent - backpropogate the network and apply a fraction of the gradients to the current weights.\"\n",
    "        # backward pass\n",
    "        for p in self.parameters:\n",
    "            p.grad = None ##zero the gradient\n",
    "\n",
    "        self.loss.backward() ##backprop\n",
    "\n",
    "        # update params\n",
    "        for p in self.parameters:\n",
    "            p.data += -lr * p.grad ##learning rate\n",
    "\n",
    "\n",
    "    def generate_jokes(self, n_words, start_words: str = None, min_length=0):\n",
    "        \"\"\"\n",
    "        Generates n_words word examples by passing n-1 random characters into the model, performing a forward pass,\n",
    "        and probabilistically choosing a character using the model's predicted probability distribution.\n",
    "        Pass n-2 start_chrs to specify the starting characters of the word generation process (first character is always '.').\n",
    "        Specify a minimum word length min_length to generate words at least that long.\n",
    "        \"\"\"\n",
    "        itow = self.itow\n",
    "        wtoi = self.wtoi\n",
    "        n_inputs = self.n_inputs\n",
    "        out_jokes = []\n",
    "\n",
    "        for _ in range(n_words):\n",
    "            joke = '.'\n",
    "            context = [0] * n_inputs\n",
    "            if start_words is not None:\n",
    "                assert len(start_words.split()) <= n_inputs, f\"Number of start words ({len(start_words.split())}) should be {n_inputs} or less.\"\n",
    "                for w in start_words.split():\n",
    "                    assert w in wtoi, f\"Start word '{w}' cannot be used since it is not in the list of training words.\"\n",
    "                    joke += \" \" + w.lower()\n",
    "                    context[1:] + [wtoi[w.lower()]]\n",
    "\n",
    "            while True:\n",
    "                # forward pass\n",
    "                probs, loss = self.forward_pass(\n",
    "                    torch.tensor([context]) #.reshape(1, n_inputs)\n",
    "                    )\n",
    "                # Get word\n",
    "                word_ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "                # determine how to proceed\n",
    "                if (word_ix==0) & (len(joke.split())-1 <= min_length): ##if the ix is 0 but the joke is too short, resample (-1 due to starting .)\n",
    "                    pass\n",
    "                elif (word_ix==0) & (len(joke.split())-1 > min_length): ##if the ix is 0 and joke is long enough, end joke and break joke creation\n",
    "                    joke += \" .\" #itow[word_ix]\n",
    "                    break\n",
    "                else:                                   ##otherwise, add to the joke and shift the context for the next forward pass\n",
    "                    joke += \" \" + itow[word_ix]\n",
    "                    ## Shift words to predict the next one\n",
    "                    context = context[1:] + [word_ix] ##shift and append  \n",
    "            out_jokes.append(joke)    \n",
    "        \n",
    "        return out_jokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(words) = 2378\n"
     ]
    }
   ],
   "source": [
    "# Read in text file - one joke per line\n",
    "with open('jokes.txt') as f:\n",
    "    jokes = f.read().splitlines()\n",
    "\n",
    "# Create list of all words used in the jokes\n",
    "words = set(' '.join([j for j in jokes]).split(' '))\n",
    "words = [w for w in words if w != \"\"] ##remove empty string\n",
    "\n",
    "print(f\"{len(words) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2379"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mappings from integer to word\n",
    "itow = {i+1 : w for i, w in enumerate(sorted(words))}\n",
    "itow[0] = '.'\n",
    "wtoi = {w : i for i, w in itow.items()}\n",
    "len(itow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n_samples = 11266\n"
     ]
    }
   ],
   "source": [
    "N = 3 ## Number of words used to predict the next word\n",
    "\n",
    "# Create dataset based on N and split into training and development sets\n",
    "X, Y = create_joke_data(jokes, block_size=N, words=words)\n",
    "Xtr, Ytr, Xdev, Ydev = split_samples(X, Y, 0.8, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params = 267169\n"
     ]
    }
   ],
   "source": [
    "# Initialize the joke model based on N and provide with list of words in data. Initialize weights based on desired model structure\n",
    "g = torch.Generator().manual_seed(123)\n",
    "\n",
    "model = OneLinerMLP(block_size=N, words=words)\n",
    "model.initialize_weights(embedding_dimensions=10,\n",
    "                         hidden_layer_neurons=100, \n",
    "                         generator=g)\n",
    "\n",
    "\n",
    "# Initialzie lists to store metrics\n",
    "losses, val_losses = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses:\n",
      "Step 0: Train - 5.35439 Dev - 5.90773\n",
      "Step 100: Train - 5.03756 Dev - 5.88353\n",
      "Step 200: Train - 4.73699 Dev - 5.88878\n",
      "Step 300: Train - 4.45304 Dev - 5.91438\n",
      "Step 400: Train - 4.1866 Dev - 5.95417\n",
      "Step 500: Train - 3.93652 Dev - 6.00392\n",
      "Step 600: Train - 3.70149 Dev - 6.06125\n",
      "Step 700: Train - 3.48031 Dev - 6.12491\n",
      "Step 800: Train - 3.27181 Dev - 6.19427\n",
      "Step 900: Train - 3.0752 Dev - 6.26901\n",
      "Step 999: Train - 2.89183 Dev - 6.34777\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "steps = 1000\n",
    "batch_size = None\n",
    "\n",
    "\n",
    "print(\"losses:\")\n",
    "for k in range(steps):\n",
    "\n",
    "    # minibatching\n",
    "    if batch_size is not None:\n",
    "        batch_ix = torch.randint(0, Xtr.shape[0], (batch_size, )) ##n_samples randints between 0 and length of data\n",
    "    else:\n",
    "        batch_ix=range(0, Xtr.shape[0]) ##all data included\n",
    "\n",
    "    # forward pass\n",
    "    probs, loss = model.forward_pass(Xtr[batch_ix], Ytr[batch_ix])\n",
    "\n",
    "    # backward pass \n",
    "    lr = 1 #lrs[k]\n",
    "    model.backprop_update(lr=lr)\n",
    "\n",
    "    # validation eval\n",
    "    with torch.no_grad():\n",
    "        _, val_loss = model.forward_pass(Xdev, Ydev)\n",
    "\n",
    "    # log updates & track stats\n",
    "    if (k in range(0, steps, int(steps*0.10))) or (k==steps-1):\n",
    "        print(f\"Step {k}:\", end=\" \")\n",
    "        print(f\"Train - {round(loss.item(), 5)}\", end=\" \")\n",
    "        print(f\"Dev - {round(val_loss.item(), 5)}\")\n",
    "    \n",
    "\n",
    "    losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    # lr_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. i next to fell is but in a job in soar when like look time steal you had be drink .',\n",
       " '. what do you call stop you are the windshield of cheerleader .',\n",
       " '. did where an your nearby them .']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_jokes(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c4359ed68c894e31dfa741bacd50703ee9ca4c289f19062f47d11ef9a0ee7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
